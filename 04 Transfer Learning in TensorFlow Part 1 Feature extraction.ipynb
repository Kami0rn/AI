{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with TensorFlow Part 1: Feature Extraction\n",
    "\n",
    "Transfer learning is leveraging a working model's existing architecture and learned pattern for our own problem\n",
    "\n",
    "There are two main benefits:\n",
    "1. Can leverage an existing  neural network architecture proven to work on problem similar to our own\n",
    "2. Can leverage on working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those pattern to our own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug 28 00:48:41 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.81                 Driver Version: 560.81         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070      WDDM  |   00000000:08:00.0  On |                  N/A |\n",
      "|  0%   44C    P8             26W /  224W |    1868MiB /   8192MiB |     23%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1532    C+G   ...les (x86)\\Battle.net\\Battle.net.exe      N/A      |\n",
      "|    0   N/A  N/A      3316    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A      3900    C+G   C:\\Microsoft VS Code\\Code.exe               N/A      |\n",
      "|    0   N/A  N/A      4972    C+G   ...on\\wallpaper_engine\\wallpaper64.exe      N/A      |\n",
      "|    0   N/A  N/A      7176    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A      8336    C+G   ...ys\\WinUI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A      8496    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9780    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     11680    C+G   ...werToys\\PowerToys.PowerLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     12096    C+G   ...05.0_x64__zpdnekdrzrea0\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A     12548    C+G   ...\\PowerToys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A     12976    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A     13060    C+G   ...UI3Apps\\PowerToys.AdvancedPaste.exe      N/A      |\n",
      "|    0   N/A  N/A     13184    C+G   ...werToys\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A     13768    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     14012    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     14064    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     14264    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     15520    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16572    C+G   ...al\\Discord\\app-1.0.9159\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     18492    C+G   ...inaries\\Win64\\EpicGamesLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A     19212    C+G   ...ne\\Binaries\\Win64\\EpicWebHelper.exe      N/A      |\n",
      "|    0   N/A  N/A     20424    C+G   ...ata\\Local\\LINE\\bin\\current\\LINE.exe      N/A      |\n",
      "|    0   N/A  N/A     20456    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     21048    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     21988    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     22812    C+G   ...pdnekdrzrea0\\XboxGameBarSpotify.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Are we using a GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and becoming one with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# # Download the file\n",
    "# url = \"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\"\n",
    "# local_zip = \"10_food_classes_10_percent.zip\"\n",
    "# with requests.get(url, stream=True) as r:\n",
    "#     r.raise_for_status()\n",
    "#     with open(local_zip, 'wb') as f:\n",
    "#         for chunk in r.iter_content(chunk_size=8192):\n",
    "#             f.write(chunk)\n",
    "\n",
    "# # Extract the downloaded ZIP file\n",
    "# with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(\".\")\n",
    "\n",
    "# # Clean up by removing the zip file\n",
    "# os.remove(local_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent\\test'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\chicken_curry'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\chicken_wings'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\fried_rice'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\grilled_salmon'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\hamburger'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\ice_cream'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\pizza'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\ramen'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\steak'.\n",
      "There are 0 directories and 250 images in '10_food_classes_10_percent\\test\\sushi'.\n",
      "There are 10 directories and 0 images in '10_food_classes_10_percent\\train'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\chicken_curry'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\chicken_wings'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\fried_rice'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\grilled_salmon'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\hamburger'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\ice_cream'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\pizza'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\ramen'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\steak'.\n",
      "There are 0 directories and 75 images in '10_food_classes_10_percent\\train\\sushi'.\n"
     ]
    }
   ],
   "source": [
    "# How many images in each folder?\n",
    "import os\n",
    "\n",
    "# Walk though 10 percent data directory and list number of files\n",
    "for dirpath,dirnames,filenames in os.walk(\"10_food_classes_10_percent\"):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data loaders (preparing the data)\n",
    "\n",
    "We'll use the ImageDataGenerator class to load in our images in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images:\n",
      "Found 750 images belonging to 10 classes.\n",
      "Testingimages:\n",
      "Found 2500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Setup data inputs\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "print(\"Training images:\")\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                                          target_size=IMAGE_SHAPE,\n",
    "                                                          batch_size=BATCH_SIZE,\n",
    "                                                          class_mode=\"categorical\")\n",
    "\n",
    "print(\"Testingimages:\")\n",
    "test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n",
    "                                                        target_size=IMAGE_SHAPE,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        class_mode=\"categorical\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up callbacks (things to run while our model trains)\n",
    "\n",
    "Callbacks are extra functionality you can add to your models to be performed during or after training. Some of the most popular callbacks:\n",
    "\n",
    "* Tracking experiment with the TensorBoard callback.\n",
    "* Model checkpoint with the ModelCheckpoint callback.\n",
    "* Stopping a model from training (before it train too long and overfits) with the EarlyStopping callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorBoard callback (functionized because we need to create a new one for each model) DD-MM-YYYY\n",
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name,experiment_name):\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    print(f\"saving TensorBoar log files to: {log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can customize the directory where your TensorBoard logs (model training metrics) get saved to whatever you like. The `log_dir` parameter we've created above is only one option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating models using TensorFlow hub\n",
    "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
    "\n",
    "Now we're going to do a similar process, except the majority of our model's layers are going to come from TensorFlow Hub.\n",
    "\n",
    "We can access pretrained models on : https://tfhub.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
